# simple script to read table from lake house
# libraries
from notebookutils import mssparkutils as mssu
import sempy.fabric as fabric
from delta.tables import *

# variables
workspace_name = "<WS_NAME>"
lakehouse_name = "<LAKE_HOUSE_NAME>"
schema = "<SCHEMA_NAME>"
table_name = "<TABLE_NAME>"

# workspace and lake house id
workspace_id = fabric.resolve_workspace_id(workspace_name)
#display(workspace_id)

lakehouse_id = mssu.lakehouse.get(lakehouse_name,workspace_id).id
#display(lakehouse_id)

# load source table into df
source_table = (f"abfss://{workspace_id}@onelake.dfs.fabric.microsoft.com/{lakehouse_id}/Tables/{schema}/{table_name}")
deltatable = DeltaTable.forPath(spark,source_table)
measure_catalogue = deltatable.toDF()

display(measure_catalogue)
